{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from EM_dataset import EM_Data, EM_Sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.optimizers import RMSprop, Adadelta, Nadam\n",
    "from keras.models import load_model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "import os\n",
    "import my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1, 2, 3\"  # 要放到下面的前面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'th'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.image_dim_ordering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my version still needs to learn\n",
    "def soft_max_loss(y_true, y_pred):\n",
    "    y_pred_l = K.log(K.clip(y_pred, K.epsilon(),1-K.epsilon()))\n",
    "    y_cal = y_true * y_pred_l  # dot is matrix mul\n",
    "    y_cal_max = K.sum(y_cal, axis=2)\n",
    "    return -K.sum(y_cal_max) / K.cast(K.prod([256, 256, 7]), dtype='float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max_loss(y_true, y_pred):\n",
    "    y_cal = y_true * y_pred\n",
    "    y_cal_max = K.sum(y_cal, axis=2)\n",
    "    return -K.sum(K.log(K.clip(y_cal_max, K.epsilon(),1-K.epsilon()))) \\\n",
    "                    /K.cast(K.prod([2, 7, 1, 256, 256]), dtype='float32')  # divided by size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myacc(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    return K.mean(K.equal(y_true_f, K.round(y_pred_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "models = {}\n",
    "\n",
    "model_dict['deepEM3D'] = ['deepEM3D', my_model.timeDist_DeepEM3D_Net]\n",
    "models['deepEM3D'] = 'deepEM3D'\n",
    "model_name = 'deepEM3D'\n",
    "\n",
    "# model_dict[model][1] return a function pointer for creating network model\n",
    "model_name = model_dict[model_name][0]\n",
    "model_create_func = model_dict[model_name][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data file from: DATA/CREMI/A_train_norm.h5\n",
      "loading data file from: DATA/CREMI/A_train_norm.h5\n"
     ]
    }
   ],
   "source": [
    "row = 256\n",
    "col = 256\n",
    "depth = 7\n",
    "params = {'patch_shape': (256,256,7),\n",
    "          'batch_size': 16,\n",
    "          'data_dir': 'DATA/CREMI/',\n",
    "          'data_file': 'A_train_norm.h5'}\n",
    "\n",
    "train_gen = EM_Sequence(**params)\n",
    "valid_gen = EM_Sequence(**params, train_flag=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMGPU(Model):\n",
    "    def __init__(self, ser_model, gpus):\n",
    "        pmodel = multi_gpu_model(ser_model, gpus)\n",
    "        self.__dict__.update(pmodel.__dict__)\n",
    "        self._smodel = ser_model\n",
    "\n",
    "    def __getattribute__(self, attrname):\n",
    "        '''Override load and save methods to be used from the serial-model. The\n",
    "        serial-model holds references to the weights in the multi-gpu model.\n",
    "        '''\n",
    "        # return Model.__getattribute__(self, attrname)\n",
    "        if 'load' in attrname or 'save' in attrname:\n",
    "            return getattr(self._smodel, attrname)\n",
    "\n",
    "        return super(ModelMGPU, self).__getattribute__(attrname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(None, 1, row, col)) \n",
    "outputs = model_create_func(inputs)\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = 'cremi2'\n",
    "weight_h5_file = exp + '-{epoch:02d}-{val_myacc:.2f}.h5'  # here use val_myacc\n",
    "folder = './logs/' + exp + '/'\n",
    "\n",
    "csv_logger = CSVLogger(folder + exp +'.log') #, append=True) \n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "best_model = ModelCheckpoint(folder + weight_h5_file, verbose=1, \n",
    "                             save_best_only=True, save_weights_only=True, period=5) \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, \n",
    "                              verbose=1, mode='min', min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = TensorBoard(log_dir=folder, write_graph=True, update_freq='epoch',\n",
    "                        )\n",
    "# histogram_freq=2, write_grads=True, write_images=True\n",
    "# won't work? basically because net archi, too much computation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 256 ms, total: 11.7 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parallel_model = ModelMGPU(model, gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1e-3 will make acc down to 0\n",
    "optimizer = RMSprop(lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one is just not working here?\n",
    "optimizer = Adadelta(lr=1e-3, rho=0.95, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All parameter gradients will be clipped to clipnorm\n",
    "# a maximum norm of 1.\n",
    "\n",
    "# All parameter gradients will be clipped to clipvalue\n",
    "# a maximum value of 0.5 and\n",
    "# a minimum value of -0.5.\n",
    "\n",
    "optimizer = Nadam(lr=0.02, beta_1=0.9, beta_2=0.999, \n",
    "                  epsilon=None, schedule_decay=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.compile(optimizer = optimizer, loss = soft_max_loss, metrics = [myacc])\n",
    "# parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "319/400 [======================>.......] - ETA: 1:18 - loss: 4.6350 - myacc: 0.7989"
     ]
    }
   ],
   "source": [
    "history = parallel_model.fit_generator(generator=train_gen,\n",
    "                              validation_data=valid_gen, \n",
    "                              steps_per_epoch=400, epochs=500, # 1024x1024x100 / 256x256x7\n",
    "                              validation_steps=50, \n",
    "                              verbose=1, workers=6, use_multiprocessing=True,\n",
    "                              callbacks = [best_model, csv_logger, reduce_lr, tb_logger])\n",
    "#tensorboard --logdir=/full_path_to_your_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
